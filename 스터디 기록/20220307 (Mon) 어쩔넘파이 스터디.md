# 20220307 (Mon) 어쩔넘파이 스터디

(수정완료)

## 1. Errors

- 403 error

```python
import ssl

headers = {'User-Agent': 'Chrome/66.0.3359.181'}
req = urllib.request.Request(df['URL'][0], headers=headers)
context = ssl._create_unverified_context()
html = urlopen(req, context=context)
soup_tmp = BeautifulSoup(html.read(), 'html.parser')
```

<br>

## 2. 질문 & 정보

> github에 jupyter notebook 올렸을 때 지도가 출력되지 않는 문제 --> 미해결(django로 polium 지도 띄울 수 있는 웹사이트 따로 만들 수 있다.)

- import 형식이라 안 되고, 따로 그림 형식으로만 올릴 수 있다.

- https://docs.github.com/en/repositories/working-with-files/using-files/working-with-non-code-files

- http://nbviewer.org/

  이 사이트에 github 주소를 입력하면 지도까지 포함하여 보여준다.

<br>

> find와 select?

#### soup.find와 soup.select의 차이

- `find`는 `html tag`를 통한 크롤링,  `select`는 `css`를 통한 크롤링에 쓰인다. 
- - 첫 번째 태그를 찾는 것은 `find, select_one `함수이고 모든 태그를 찾는 것은 `find_all, select `함수 
  - - 가장 큰 차이점은 `select`는` > `로 하위태그를 쉽게 찾을 수 있다. 
    - - 예를 들어`head `태그 아래있는` title`태그를 찾고 싶다고 할때, `select`가 더 직관적인 형태로 태그를 찾을 수 있다. 
      - - `find_all - class_='outertext'`-> 첫 번째 태그 가져옴

<br>

> 승훈

#### tqdm warning 뜨지 않도록 하는 법

```python
from tqdm import notebook

for n in notebook.tqdm(df.index): # 이렇게 쓰니까 워닝이 안뜨네
```

<br>

> 교수님

#### urllib 사용하지 않고 가져오는 법

```python
import requests
url = "https://movie.naver.com/movie/sdb/rank/rmovie.nhn?sel=cur&date=2021-12-12"
response = requests.get(url).text 
html = urlopen(request).read().decode()
soup_tmp = BeautifulSoup(html, "html.parser")
soup_tmp
```

![unknown](20220307%20(Mon)%20%EC%96%B4%EC%A9%94%EB%84%98%ED%8C%8C%EC%9D%B4%20%EC%8A%A4%ED%84%B0%EB%94%94.assets/unknown.png)

<br>

> 혜린

#### 정규표현식

#### \n, \r\n

- 혜린 jupyter notebook에서 설명 확인

<br>

> 경욱

#### 크롤링할 때 robots.txt 잘 읽어보기

https://namu.wiki/w/robots.txt

<br>

## 3. 회고

> 완택

크롤링 많이 해봤었는데, 복습을 많이 안하다보니까 할 때마다 까먹어서 오늘부터 복습하고 정리해서 해야겠다.

<br>

> 경욱

예전에 크롤링 해볼 때는 태그의 의미들도 잘 모르고, 구성도 잘 모른 채로 했었는데, 최근에 html이나 bootstrap 해보면서 좀 친해졌다 생각한다. p라든지 div 등등.. 지금 와서 보니까 저번에 했던 생각이 나면서 처음 했던 거 보다는 빠르게 이해를 할 수 있었다.

<br>

> 승훈

정처기, 이것저것 하고 있었는데 이제 좀 진득하게 할 수 있는 시간이 생겨가지고 1, 2장 복습도 할 수 있을 것 같다.

<br>

> 하평

승훈님과 비슷하게 정처기 공부 한다고 집중을 많이 못했는데 못했던 부분들도 많이 해야 할 것 같다. 마지막 pivot 테이블에서 막혀 있는데 오류 잘 해결해서 잘 해보고 싶다.

<br>

> 미애

1, 2장을 좀 제대로 못해서 3장을 계속 봤는데 에러도 똑같은 부분이 나왔다. 또 뭔가 html 이런 내용 나오고, url 다루는 관통 프로젝트도 했었는데, 낯이 익으면서도 좀 어색한 느낌으로 쓰면서 이렇게 쓸 수도 있구나라고 느꼈다. 뭔가 자연스럽게 관통당하고 있다는 느낌이 들었다.

<br>

> 혜린

3장 하면서 조금 더 숨통이 트이는 느낌. 말씀해주신대로 더 익숙한 느낌이고 수업 시간에 배웠던 html 기반으로 크롤링을 하는 것이다보니 더 재미있게 할 수 있었다!